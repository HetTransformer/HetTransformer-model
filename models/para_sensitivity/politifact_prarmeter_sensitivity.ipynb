{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b07cd544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.nn.init as init\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm, trange\n",
    "import torch.optim as optim\n",
    "from os import path\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from torch_position_embedding import PositionEmbedding\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbcfb1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load posts: 100%|██████████| 89/89 [03:42<00:00,  2.50s/it]\n",
      "load users: 100%|██████████| 94/94 [04:02<00:00,  2.58s/it]\n",
      "load news: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# news-news; news-post; post-user; user-user\n",
    "\n",
    "\n",
    "class Het_Node():\n",
    "    def __init__(self, node_type, node_id, embed, neighbor_list_news=[], neighbor_list_post=[], neighbor_list_user=[],\n",
    "                 label=None):\n",
    "        self.node_type = node_type\n",
    "        self.node_id = node_id\n",
    "        self.emb = embed\n",
    "        self.label = label  # only post node, user node = default = None\n",
    "        self.neighbors_news = neighbor_list_news  # [(id)]\n",
    "        self.neighbors_post = neighbor_list_post\n",
    "        self.neighbors_user = neighbor_list_user\n",
    "\n",
    "def neighbor_loader(pathway):\n",
    "    neighbor_dict_post = {}\n",
    "    neighbor_dict_user = {}\n",
    "    neighbor_dict_news = {}\n",
    "    neighbor_dict_n_p_u = {}\n",
    "    neighbor_dict_n = {}\n",
    "    f = open(pathway)\n",
    "    Lines = f.readlines()\n",
    "    for i in range(len(Lines)):\n",
    "        neighbor_list = Lines[i].split()\n",
    "        neighbor_dict_n_p_u[neighbor_list[0][1:-1]] = [(item[0], item[1:]) for item in neighbor_list[1:] if item[0] == 'p' or item[0] == 'u']\n",
    "        neighbor_dict_n[neighbor_list[0][1:-1]] = [(item[0], item[1:]) for item in neighbor_list[1:] if item[0] == 'n']\n",
    "        neighbor_dict_news[neighbor_list[0][1:-1]] = [item[1:] for item in neighbor_list[1:] if item[0] == 'n']\n",
    "        neighbor_dict_user[neighbor_list[0][1:-1]] = [item[1:] for item in neighbor_list[1:] if item[0] == 'u']\n",
    "        neighbor_dict_post[neighbor_list[0][1:-1]] = [item[1:] for item in neighbor_list[1:] if item[0] == 'p']\n",
    "    return neighbor_dict_n_p_u, neighbor_dict_n, neighbor_dict_news, neighbor_dict_post, neighbor_dict_user\n",
    "\n",
    "neighbor_dict = neighbor_loader('model/data_splits/PolitiFact/n_neighbors.txt')\n",
    "#print(list(neighbor_dict[2].values())[:5])\n",
    "#print(list(neighbor_dict[3].values())[:5])\n",
    "#print(list(neighbor_dict[4].values())[:5])\n",
    "\n",
    "def data_loader(pathway='\', node_type=\"post\"):\n",
    "    if node_type == \"news\":\n",
    "        \n",
    "        news_node = []\n",
    "        news_id = []\n",
    "        news_label = []\n",
    "        news_embed = []\n",
    "        news_n_neigh = []\n",
    "        news_p_neigh = []\n",
    "        news_u_neigh = []\n",
    "        for i in trange(1, desc='load news'):\n",
    "            # print(i)\n",
    "            batch = str(i)\n",
    "            f = open(pathway + \"batch_\" + batch + '.txt')\n",
    "            # print(pathway + \"batch_\" + batch + '.txt')\n",
    "            Lines = f.readlines()\n",
    "            for j in range(len(Lines)):\n",
    "                if j < len(Lines):\n",
    "                    if j % 7 == 0:\n",
    "                        _, id_, label = Lines[j].split()\n",
    "                        news_id.append(id_)\n",
    "                        news_label.append(int(label))\n",
    "                        embed = []\n",
    "                    if j % 7 == 1 or j % 7 == 2 or j % 7 == 3:\n",
    "                        embed.append(list(map(float, Lines[j].split())))\n",
    "                    if j % 7 == 3:\n",
    "                        news_embed.append(embed)\n",
    "                    \n",
    "            f.close()\n",
    "        for i in range(len(news_id)):\n",
    "            node = Het_Node(node_type=\"news\", node_id=news_id[i], embed=news_embed[i], label=news_label[i])\n",
    "            news_node.append(node)\n",
    "        # padding_node = Het_Node(node_type=\"news\", node_id=padding_id, embed=padding_embed,\n",
    "                            # neighbor_list_news=padding_news_n_neigh, neighbor_list_post=padding_news_p_neigh, neighbor_list_user=padding_news_u_neigh)\n",
    "        return news_node# , padding_node\n",
    "\n",
    "    elif node_type == 'post':\n",
    "        post_node = []\n",
    "        post_id = []\n",
    "        post_embed = []\n",
    "        for i in trange(89, desc=\"load posts\"):\n",
    "            # print(i)\n",
    "            batch = str(i)\n",
    "            f = open(pathway + \"batch_\" + batch + '.txt')\n",
    "            # print(pathway + \"batch_\" + batch + '.txt')\n",
    "            Lines = f.readlines()\n",
    "            for j in range(len(Lines)):\n",
    "                if j < len(Lines):\n",
    "                    if j % 6 == 0:\n",
    "                        id_ = Lines[j].split()\n",
    "                        post_id.append(id_[1])\n",
    "                        embed = []\n",
    "                    if j % 6 == 1 or j % 6 == 2:\n",
    "                        embed.append(list(map(float, Lines[j].split())))\n",
    "                    if j % 6 == 2:\n",
    "                        post_embed.append(embed)\n",
    "            f.close()\n",
    "        for i in range(len(post_id)):\n",
    "            node = Het_Node(node_type=\"post\", node_id=post_id[i], embed=post_embed[i])\n",
    "            post_node.append(node)\n",
    "        # padding_node = Het_Node(node_type='post', node_id=padding_id, embed=padding_embed)\n",
    "        return post_node# , padding_node\n",
    "\n",
    "    else:\n",
    "        user_node = []\n",
    "        user_id = []\n",
    "        user_embed = []\n",
    "        for i in trange(94, desc=\"load users\"):\n",
    "            # print(i)\n",
    "            batch = str(i)\n",
    "            f = open(pathway + \"batch_\" + batch + '.txt')\n",
    "            # print(pathway + \"batch_\" + batch + '.txt')\n",
    "            Lines = f.readlines()\n",
    "            for j in range(len(Lines)):               \n",
    "                if j < len(Lines):\n",
    "                    if j % 6 == 0:\n",
    "                        id_ = Lines[j].split()\n",
    "                        user_id.append(id_[1])\n",
    "                        embed = []\n",
    "                    if j % 6 == 1 or j % 6 == 2:\n",
    "                        embed.append(list(map(float, Lines[j].split())))\n",
    "                    if j % 6 == 2:\n",
    "                        user_embed.append(embed)\n",
    "            f.close()\n",
    "        for i in range(len(user_id)):\n",
    "            node = Het_Node(node_type=\"user\", node_id=user_id[i], embed=user_embed[i])\n",
    "            user_node.append(node)\n",
    "        # padding_node = Het_Node(node_type='user', node_id=padding_id, embed=padding_embed)\n",
    "        return user_node#, padding_node\n",
    "    \n",
    "post_nodes = data_loader(pathway='FakeNewsNet/FNN_input/Politifact/fnn_politifact_512/normalized_post_nodes/', node_type=\"post\")\n",
    "user_nodes = data_loader(pathway='FakeNewsNet/FNN_input/Politifact/fnn_politifact_512/normalized_user_nodes/', node_type=\"user\")\n",
    "news_nodes = data_loader(pathway='FakeNewsNet/FNN_input/Politifact/fnn_politifact_512/normalized_news_nodes/', node_type=\"news\")\n",
    "# neighbor_dict = neighbor_loader('fnn_politifact_200/n_neighbors.txt')\n",
    "news_emb_dict = {}\n",
    "post_emb_dict = {}\n",
    "user_emb_dict = {}\n",
    "\n",
    "for user in user_nodes:\n",
    "    user_emb_dict[user.node_id] = user.emb\n",
    "for post in post_nodes:\n",
    "    post_emb_dict[post.node_id] = post.emb\n",
    "for news in news_nodes:\n",
    "    news_emb_dict[news.node_id] = news.emb\n",
    "    \n",
    "#user_emb_dict[u_padding.node_id] = u_padding.emb\n",
    "#post_emb_dict[p_padding.node_id] = p_padding.emb\n",
    "#news_emb_dict[n_padding.node_id] = n_padding.emb\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4434315a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of fake nodes:  385\n",
      "number of real nodes:  401\n"
     ]
    }
   ],
   "source": [
    "news_nodes_real = []\n",
    "news_nodes_fake = []\n",
    "for node in news_nodes:\n",
    "    if node.label == 1:\n",
    "        news_nodes_real.append(node)\n",
    "    else:\n",
    "        news_nodes_fake.append(node)\n",
    "print(\"number of fake nodes: \", len(news_nodes_fake))\n",
    "print(\"number of real nodes: \", len(news_nodes_real))\n",
    "#fake : real = 0.9842 : 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        #print(self.pe[:x.size(0), :].shape)\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class NeighborTypeEmbedding(nn.Embedding):\n",
    "    def __init__(self, num_node_type=3, embed_size=512):\n",
    "        super().__init__(num_node_type, embed_size, padding_idx=0)\n",
    "\n",
    "        \n",
    "class Het_GNN(nn.Module):\n",
    "    # features: list of HetNode class\n",
    "    def __init__(self, input_dim, ini_hidden_dim, hidden_dim,\n",
    "                 n_hidden_dim, n_ini_hidden_dim, n_output_dim,\n",
    "                 u_hidden_dim, u_ini_hidden_dim, u_output_dim,\n",
    "                 p_hidden_dim, p_ini_hidden_dim, p_output_dim,\n",
    "                 out_embed_d,\n",
    "                 outemb_d=1, n_num_layers=1, u_num_layers=1, p_num_layers=1, num_layers=1, n_batch_size=1,\n",
    "                 u_batch_size=1, p_batch_size=1, content_dict={}, n_rnn_type='LSTM', u_rnn_type='LSTM',\n",
    "                 p_rnn_type='LSTM',\n",
    "                 rnn_type='LSTM', embed_d=200, symmetry=False, GCN_out2=300, GCN_out1=600, GCN_in=200, use_bias=True, attn_heads = 2, d_model = 512, use_gcn = True, enc_layers=1, npu = 15):\n",
    "        super(Het_GNN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.ini_hidden_dim = ini_hidden_dim\n",
    "        self.hidden_dim = out_embed_d\n",
    "        self.num_layers = num_layers\n",
    "        self.embed_d = out_embed_d\n",
    "        self.n_input_dim = out_embed_d\n",
    "        self.n_hidden_dim = n_hidden_dim\n",
    "        self.n_ini_hidden_dim = n_ini_hidden_dim\n",
    "        self.n_batch_size = n_batch_size\n",
    "        self.n_output_dim = out_embed_d\n",
    "        self.n_num_layers = n_num_layers\n",
    "        self.n_rnn_type = n_rnn_type\n",
    "        self.u_input_dim = out_embed_d\n",
    "        self.u_hidden_dim = u_hidden_dim\n",
    "        self.u_ini_hidden_dim = u_ini_hidden_dim\n",
    "        self.u_batch_size = u_batch_size\n",
    "        self.u_output_dim = out_embed_d\n",
    "        self.u_num_layers = u_num_layers\n",
    "        self.u_rnn_type = u_rnn_type\n",
    "        self.p_input_dim = out_embed_d\n",
    "        self.p_hidden_dim = p_hidden_dim\n",
    "        self.p_ini_hidden_dim = p_ini_hidden_dim\n",
    "        self.p_batch_size = p_batch_size\n",
    "        self.p_output_dim = out_embed_d\n",
    "        self.p_num_layers = p_num_layers\n",
    "        self.p_rnn_type = p_rnn_type\n",
    "        self.d_model = d_model\n",
    "        self.npu = npu\n",
    "        self.out_embed_d = out_embed_d\n",
    "        # self.out_linear_d = out_linear\n",
    "        self.outemb_d = outemb_d\n",
    "        # self.features = features\n",
    "        self.content_dict = content_dict\n",
    "        self.GCN_in = out_embed_d\n",
    "        self.GCN_out1 = GCN_out1\n",
    "        self.GCN_out2 = out_embed_d * 2\n",
    "        self.use_bias = use_bias\n",
    "        self.symmetry = symmetry\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout=0.1, max_len=npu+1)\n",
    "        self.pos_decoder = PositionalEncoding(d_model, dropout=0.1, max_len=npu+1)\n",
    "        self.type_encoder = nn.Embedding(3, d_model, padding_idx=0)\n",
    "        self.use_gcn = use_gcn\n",
    "        self.n_neigh_att = nn.Parameter(torch.ones(self.embed_d * 2, 1), requires_grad=True)\n",
    "        self.p_neigh_att = nn.Parameter(torch.ones(self.embed_d * 2, 1), requires_grad=True)\n",
    "        self.u_neigh_att = nn.Parameter(torch.ones(self.embed_d * 2, 1), requires_grad=True)\n",
    "        self.GCN_W1_user = torch.nn.Parameter(torch.FloatTensor(self.GCN_in, self.GCN_out1), requires_grad=True)\n",
    "        self.GCN_W2_user = torch.nn.Parameter(torch.FloatTensor(self.GCN_out1, self.GCN_out2), requires_grad=True)\n",
    "        self.GCN_W1_post = torch.nn.Parameter(torch.FloatTensor(self.GCN_in, self.GCN_out1), requires_grad=True)\n",
    "        self.GCN_W2_post = torch.nn.Parameter(torch.FloatTensor(self.GCN_out1, self.GCN_out2), requires_grad=True)\n",
    "        self.GCN_W1_news = torch.nn.Parameter(torch.FloatTensor(self.GCN_in, self.GCN_out1), requires_grad=True)\n",
    "        self.GCN_W2_news = torch.nn.Parameter(torch.FloatTensor(self.GCN_out1, self.GCN_out2), requires_grad=True)\n",
    "        if self.use_bias:\n",
    "            self.user_bias1 = nn.Parameter(torch.Tensor(self.GCN_out1), requires_grad=True)\n",
    "            self.post_bias1 = nn.Parameter(torch.Tensor(self.GCN_out1), requires_grad=True)\n",
    "            self.news_bias1 = nn.Parameter(torch.Tensor(self.GCN_out1), requires_grad=True)\n",
    "            self.user_bias2 = nn.Parameter(torch.Tensor(self.GCN_out2), requires_grad=True)\n",
    "            self.post_bias2 = nn.Parameter(torch.Tensor(self.GCN_out2), requires_grad=True)\n",
    "            self.news_bias2 = nn.Parameter(torch.Tensor(self.GCN_out2), requires_grad=True)\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.transformer = nn.Transformer(d_model=d_model, nhead=attn_heads, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=512, \n",
    "                                          dropout=0.1, activation='relu', custom_encoder=None, custom_decoder=None)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=attn_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=enc_layers)\n",
    "        # self.node_type_iput = NeighborTypeEmbedding(num_node_type=3, embed_size=self.d_model)\n",
    "        # self.positional_embedding = PositionalEncoding(self.d_model, dropout=0.1, max_len=5000)\n",
    "        # Define the initial linear hidden layer\n",
    "        \n",
    "        \n",
    "        self.init_linear_text = nn.Linear(self.input_dim[0], self.hidden_dim)\n",
    "        self.init_linear_image = nn.Linear(self.input_dim[1], self.hidden_dim)\n",
    "        self.init_linear_other = nn.Linear(self.input_dim[2], self.hidden_dim)\n",
    "        self.init_linear_other_user = nn.Linear(self.input_dim[3], self.hidden_dim)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.init_linear_text = nn.Linear(self.input_dim[0], self.ini_hidden_dim[0])\n",
    "        self.init_linear_image = nn.Linear(self.input_dim[1], self.ini_hidden_dim[1])\n",
    "        self.init_linear_other = nn.Linear(self.input_dim[2], self.ini_hidden_dim[2])\n",
    "        self.init_linear_other_user = nn.Linear(self.input_dim[3], self.ini_hidden_dim[3])\n",
    "        \"\"\"\n",
    "        # Define the attention layer\n",
    "        self.news_title_LSTM_text = eval('nn.' + rnn_type)(self.ini_hidden_dim[0], self.hidden_dim, self.num_layers,\n",
    "                                                           batch_first=True,\n",
    "                                                           bidirectional=True, dropout=0.5)\n",
    "        self.news_title_attention_text = nn.MultiheadAttention(self.hidden_dim, attn_heads, dropout = 0.2)\n",
    "        self.news_content_LSTM_text = eval('nn.' + rnn_type)(self.ini_hidden_dim[0], self.hidden_dim, self.num_layers,\n",
    "                                                             batch_first=True,\n",
    "                                                             bidirectional=True, dropout=0.5)\n",
    "        self.news_content_attention_text = nn.MultiheadAttention(self.hidden_dim, attn_heads, dropout = 0.2)\n",
    "        self.post_content_LSTM_text = eval('nn.' + rnn_type)(self.ini_hidden_dim[0], self.hidden_dim, self.num_layers,\n",
    "                                                             batch_first=True,\n",
    "                                                             bidirectional=True, dropout=0.5)\n",
    "        self.post_content_attention_text = nn.MultiheadAttention(self.hidden_dim, attn_heads, dropout = 0.2)\n",
    "        self.user_content_LSTM_text = eval('nn.' + rnn_type)(self.ini_hidden_dim[0], self.hidden_dim, self.num_layers,\n",
    "                                                             batch_first=True,\n",
    "                                                             bidirectional=True, dropout=0.5)\n",
    "        self.user_content_attention_text = nn.MultiheadAttention(self.hidden_dim, attn_heads, dropout = 0.2)\n",
    "        self.LSTM_image = eval('nn.' + rnn_type)(self.ini_hidden_dim[1], self.hidden_dim, self.num_layers,\n",
    "                                                 batch_first=True,\n",
    "                                                 bidirectional=True, dropout=0.5)\n",
    "        self.attention_image = nn.MultiheadAttention(self.hidden_dim, attn_heads, dropout = 0.2)\n",
    "        self.LSTM_other = eval('nn.' + rnn_type)(self.ini_hidden_dim[2], self.hidden_dim, self.num_layers,\n",
    "                                                 batch_first=True,\n",
    "                                                 bidirectional=True, dropout=0.5)\n",
    "        self.attention_other = nn.MultiheadAttention(self.hidden_dim, attn_heads, dropout = 0.2)\n",
    "        self.LSTM_other_user = eval('nn.' + rnn_type)(self.ini_hidden_dim[3], self.hidden_dim, self.num_layers,\n",
    "                                                 batch_first=True,\n",
    "                                                 bidirectional=True, dropout=0.5)\n",
    "        self.LSTM_other_user = nn.MultiheadAttention(self.hidden_dim, attn_heads, dropout = 0.2)\n",
    "        self.layernorm1 = nn.LayerNorm([1,out_embed_d])\n",
    "        self.layernorm2 = nn.LayerNorm([1,out_embed_d])\n",
    "        self.layernorm3 = nn.LayerNorm([1,out_embed_d])\n",
    "        self.layernorm4 = nn.LayerNorm([1,out_embed_d])\n",
    "        self.layernorm5 = nn.LayerNorm([1,out_embed_d])\n",
    "        # Define same_type_agg\n",
    "        self.n_init_linear = nn.Linear(self.n_input_dim, self.n_hidden_dim)\n",
    "        # self.n_init_linear = nn.Linear(self.n_input_dim, self.n_ini_hidden_dim)\n",
    "        # self.u_init_dropout = nn.Dropout(p=0.2)\n",
    "        self.n_LSTM = eval('nn.' + self.n_rnn_type)(self.n_ini_hidden_dim, self.n_hidden_dim, self.n_num_layers,\n",
    "                                                    batch_first=True, bidirectional=True, dropout=0.5)\n",
    "        self.n_attention = nn.MultiheadAttention(self.n_hidden_dim, attn_heads, dropout = 0.2)\n",
    "        self.n_linear = nn.Linear(self.n_hidden_dim, self.n_output_dim)\n",
    "        self.n_dropout = nn.Dropout(p=0.5)\n",
    "        self.u_init_linear = nn.Linear(self.u_input_dim, self.u_hidden_dim)\n",
    "        # self.u_init_linear = nn.Linear(self.u_input_dim, self.u_ini_hidden_dim)\n",
    "        # self.u_init_dropout = nn.Dropout(p=0.2)\n",
    "        self.u_LSTM = eval('nn.' + self.u_rnn_type)(self.u_ini_hidden_dim, self.u_hidden_dim, self.u_num_layers,\n",
    "                                                    batch_first=True, bidirectional=True, dropout=0.5)\n",
    "        self.u_attention = nn.MultiheadAttention(self.u_hidden_dim, attn_heads, dropout = 0.2)\n",
    "        self.u_linear = nn.Linear(self.u_hidden_dim, self.u_output_dim)\n",
    "        self.u_dropout = nn.Dropout(p=0.5)\n",
    "        self.p_init_linear = nn.Linear(self.p_input_dim, self.p_hidden_dim)\n",
    "        # self.p_init_linear = nn.Linear(self.p_input_dim, self.p_ini_hidden_dim)\n",
    "        # self.p_init_dropout = nn.Dropout(p=0.2)\n",
    "        self.p_LSTM = eval('nn.' + self.p_rnn_type)(self.p_ini_hidden_dim, self.p_hidden_dim, self.p_num_layers,\n",
    "                                                    batch_first=True, bidirectional=True, dropout=0.5)\n",
    "        self.p_attention = nn.MultiheadAttention(self.p_hidden_dim, attn_heads, dropout = 0.2)\n",
    "        self.p_linear = nn.Linear(self.p_hidden_dim, self.p_output_dim)\n",
    "        self.p_dropout = nn.Dropout(p=0.5)\n",
    "        self.act = nn.LeakyReLU()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.out_dropout = nn.Dropout(p=0.25)\n",
    "        self.out_linear = nn.Linear(self.out_embed_d, self.outemb_d)\n",
    "\n",
    "        # self.out_final = nn.Linear(self.out_linear_d, self.outemb_d)\n",
    "        self.output_act = nn.Sigmoid()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear) or isinstance(m, nn.Parameter):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                m.bias.data.fill_(0.1)\n",
    "        nn.init.kaiming_uniform_(self.GCN_W1_user)\n",
    "        nn.init.kaiming_uniform_(self.GCN_W1_post)\n",
    "        nn.init.kaiming_uniform_(self.GCN_W1_news)\n",
    "        nn.init.kaiming_uniform_(self.GCN_W2_user)\n",
    "        nn.init.kaiming_uniform_(self.GCN_W2_post)\n",
    "        nn.init.kaiming_uniform_(self.GCN_W2_news)\n",
    "        if self.use_bias:\n",
    "            nn.init.zeros_(self.user_bias1)\n",
    "            nn.init.zeros_(self.post_bias1)\n",
    "            nn.init.zeros_(self.news_bias1)\n",
    "            nn.init.zeros_(self.user_bias2)\n",
    "            nn.init.zeros_(self.post_bias2)\n",
    "            nn.init.zeros_(self.news_bias2)\n",
    "\n",
    "    def init_adj_degree(self, neighbor_id):\n",
    "        adj_dim = len(neighbor_id)\n",
    "        adj = np.ones((adj_dim, adj_dim))\n",
    "        degree = np.diag(np.sum(adj, axis=0))\n",
    "        return adj, degree\n",
    "\n",
    "    \"\"\"\n",
    "    def init_matrices(self, user_neighbor_id, post_neighbor_id, user_emb_dict, post_emb_dict):\n",
    "        user_H = []\n",
    "        post_H = []\n",
    "        for i in user_neighbor_id:\n",
    "            user_H.append(user_emb_dict[i][1])\n",
    "        for j in post_neighbor_id:\n",
    "            post_H.append(post_emb_dict[j][0])\n",
    "        user_A, user_D = self.init_adj_degree(user_neighbor_id)\n",
    "        post_A, post_D = self.init_adj_degree(post_neighbor_id)\n",
    "        user_H = torch.Tensor(user_H)\n",
    "        user_A = torch.Tensor(user_A)\n",
    "        user_D = torch.Tensor(user_D)\n",
    "        post_H = torch.Tensor(post_H)\n",
    "        post_A = torch.Tensor(post_A)\n",
    "        post_D = torch.Tensor(post_D)\n",
    "        return user_A, user_D, user_H, post_A, post_D, post_H\n",
    "    \"\"\"\n",
    "\n",
    "    def init_matrices(self, u_aft_rnn_dict, p_aft_rnn_dict, n_aft_rnn_dict):\n",
    "        user_H = []\n",
    "        post_H = []\n",
    "        news_H = []\n",
    "        user_H_d = u_aft_rnn_dict.values()\n",
    "        post_H_d = p_aft_rnn_dict.values()\n",
    "        news_H_d = n_aft_rnn_dict.values()\n",
    "        for i in user_H_d:\n",
    "            i = i.view(1, i.shape[0])\n",
    "            user_H.append(i)\n",
    "        for j in post_H_d:\n",
    "            j = j.view(1, j.shape[0])\n",
    "            post_H.append(j)\n",
    "        for k in news_H_d:\n",
    "            k = k.view(1, k.shape[0])\n",
    "            news_H.append(k)\n",
    "        user_A, user_D = self.init_adj_degree(u_aft_rnn_dict)\n",
    "        post_A, post_D = self.init_adj_degree(p_aft_rnn_dict)\n",
    "        news_A, news_D = self.init_adj_degree(n_aft_rnn_dict)\n",
    "        user_H = torch.cat(user_H, dim=0)\n",
    "        post_H = torch.cat(post_H, dim=0)\n",
    "        news_H = torch.cat(news_H, dim=0)\n",
    "        user_A = torch.Tensor(user_A)\n",
    "        user_D = torch.Tensor(user_D)\n",
    "        post_A = torch.Tensor(post_A)\n",
    "        post_D = torch.Tensor(post_D)\n",
    "        news_A = torch.Tensor(news_A)\n",
    "        news_D = torch.Tensor(news_D)\n",
    "        return user_A, user_D, user_H, post_A, post_D, post_H, news_A, news_D, news_H\n",
    "\n",
    "    def GCN_layer(self, user_A, user_D, user_H, post_A, post_D, post_H, news_A, news_D, news_H, layer_index):\n",
    "        if self.symmetry == False:\n",
    "            user_in = torch.mm(torch.inverse(user_D), user_A)\n",
    "            post_in = torch.mm(torch.inverse(post_D), post_A)\n",
    "            news_in = torch.mm(torch.inverse(news_D), news_A)\n",
    "        else:\n",
    "            user_D_head = fractional_matrix_power(user_D, -0.5)\n",
    "            post_D_head = fractional_matrix_power(post_D, -0.5)\n",
    "            news_D_head = fractional_matrix_power(news_D, -0.5)\n",
    "            user_D_head = torch.Tensor(user_D_head)\n",
    "            post_D_head = torch.Tensor(post_D_head)\n",
    "            news_D_head = torch.Tensor(news_D_head)\n",
    "            user_in = torch.mm(torch.mm(user_D_head, user_A), user_D_head)\n",
    "            post_in = torch.mm(torch.mm(post_D_head, post_A), post_D_head)\n",
    "            news_in = torch.mm(torch.mm(news_D_head, news_A), news_D_head)\n",
    "        user_in_features = torch.mm(user_in, user_H)\n",
    "        post_in_features = torch.mm(post_in, post_H)\n",
    "        news_in_features = torch.mm(news_in, news_H)\n",
    "        if layer_index == 1:\n",
    "            user_output = torch.mm(user_in_features, self.GCN_W1_user)\n",
    "            post_output = torch.mm(post_in_features, self.GCN_W1_post)\n",
    "            news_output = torch.mm(news_in_features, self.GCN_W1_news)\n",
    "            if self.use_bias:\n",
    "                user_output += self.user_bias1\n",
    "                post_output += self.post_bias1\n",
    "                news_output += self.news_bias1\n",
    "        else:\n",
    "            user_output = torch.mm(user_in_features, self.GCN_W2_user)\n",
    "            post_output = torch.mm(post_in_features, self.GCN_W2_post)\n",
    "            news_output = torch.mm(news_in_features, self.GCN_W2_news)\n",
    "            if self.use_bias:\n",
    "                user_output += self.user_bias2\n",
    "                post_output += self.post_bias2\n",
    "                news_output += self.news_bias2\n",
    "        return user_output, post_output, news_output\n",
    "\n",
    "    def GCN_net(self, u_aft_rnn_dict, p_aft_rnn_dict, n_aft_rnn_dict):\n",
    "        user_A, user_D, user_H, post_A, post_D, post_H, news_A, news_D, news_H = self.init_matrices(u_aft_rnn_dict,\n",
    "                                                                                                    p_aft_rnn_dict,\n",
    "                                                                                                    n_aft_rnn_dict)\n",
    "        gcn1_user, gcn1_post, gcn1_news = self.GCN_layer(user_A, user_D, user_H, post_A, post_D, post_H, news_A, news_D,\n",
    "                                                         news_H, 1)\n",
    "        gcn1_user = self.relu(gcn1_user)\n",
    "        gcn1_post = self.relu(gcn1_post)\n",
    "        gcn1_news = self.relu(gcn1_news)\n",
    "        gcn2_user, gcn2_post, gcn2_news = self.GCN_layer(user_A, user_D, gcn1_user, post_A, post_D, gcn1_post, news_A,\n",
    "                                                         news_D, gcn1_news, 2)\n",
    "        gcn2_user = torch.mean(gcn2_user, 0)\n",
    "        gcn2_post = torch.mean(gcn2_post, 0)\n",
    "        gcn2_news = torch.mean(gcn2_news, 0)\n",
    "        gcn2_user = gcn2_user.view(1, gcn2_user.shape[0])\n",
    "        gcn2_post = gcn2_post.view(1, gcn2_post.shape[0])\n",
    "        gcn2_news = gcn2_news.view(1, gcn2_news.shape[0])\n",
    "        gcn2_user = self.softmax(gcn2_user)\n",
    "        gcn2_post = self.softmax(gcn2_post)\n",
    "        gcn2_news = self.softmax(gcn2_news)\n",
    "        return gcn2_user, gcn2_post, gcn2_news\n",
    "\n",
    "    def Bi_RNN(self, neighbor_id, node_type, post_emb_dict, user_emb_dict, news_emb_dict):\n",
    "        # Forward pass through initial hidden layer\n",
    "        new_id = []\n",
    "        if node_type == \"news\":\n",
    "            input_title = []\n",
    "            input_content = []\n",
    "            input_image = []\n",
    "            for i in neighbor_id:\n",
    "                if (\"news\", i) not in self.content_dict:\n",
    "                    input_title.append(news_emb_dict[i][0])\n",
    "                    input_content.append(news_emb_dict[i][1])\n",
    "                    input_image.append(news_emb_dict[i][2])\n",
    "                    new_id.append(i)\n",
    "            input_title = torch.Tensor(input_title)\n",
    "            input_image = torch.Tensor(input_image)\n",
    "            input_content = torch.Tensor(input_content)\n",
    "            linear_input_title = self.init_linear_text(input_title)\n",
    "            linear_input_content = self.init_linear_text(input_content)\n",
    "            linear_input_image = self.init_linear_image(input_image)\n",
    "            linear_input_title = linear_input_title.view(linear_input_title.shape[0], 1, linear_input_title.shape[1])\n",
    "            linear_input_content = linear_input_content.view(linear_input_content.shape[0], 1,\n",
    "                                                             linear_input_content.shape[1])\n",
    "            linear_input_image = linear_input_image.view(linear_input_image.shape[0], 1, linear_input_image.shape[1])\n",
    "            attention_out_title, self.hidden_text = self.news_title_attention_text(linear_input_title, linear_input_title, linear_input_title)\n",
    "            attention_out_content, self.hidden_text = self.news_content_attention_text(linear_input_content, linear_input_content, linear_input_content)\n",
    "            attention_out_image, self.hidden_image = self.attention_image(linear_input_image, linear_input_image, linear_input_image)\n",
    "            attention_out_title = self.layernorm1(attention_out_title)\n",
    "            attention_out_content = self.layernorm2(attention_out_content)\n",
    "            concate = torch.cat((attention_out_title, attention_out_content, attention_out_image), 1)\n",
    "        if node_type == \"post\":\n",
    "            input_a = []\n",
    "            for i in neighbor_id:\n",
    "                if (\"post\", i) not in self.content_dict:\n",
    "                    input_a.append(post_emb_dict[i][1])\n",
    "                    # input_b.append(post_emb_dict[i][1])\n",
    "                    new_id.append(i)\n",
    "            input_a = torch.Tensor(input_a)\n",
    "            # input_b = torch.Tensor(input_b)\n",
    "            linear_input_text = self.init_linear_text(input_a)\n",
    "            # linear_input_image = self.init_linear_image(input_b)\n",
    "            linear_input_text = linear_input_text.view(linear_input_text.shape[0], 1, linear_input_text.shape[1])\n",
    "            # linear_input_image = linear_input_image.view(linear_input_image.shape[0], 1, linear_input_image.shape[1])\n",
    "            attention_out_text, self.hidden_text = self.post_content_attention_text(linear_input_text, linear_input_text, linear_input_text)\n",
    "            attention_out_text = self.layernorm3(attention_out_text)\n",
    "            # LSTM_out_image, self.hidden_image = self.LSTM_image(linear_input_image)\n",
    "            concate = attention_out_text\n",
    "        if node_type == \"user\":\n",
    "            input_a = []\n",
    "            input_b = []\n",
    "            for i in neighbor_id:\n",
    "                if (\"user\", i) not in self.content_dict:\n",
    "                    input_a.append(user_emb_dict[i][0])\n",
    "                    input_b.append(user_emb_dict[i][1])\n",
    "                    new_id.append(i)\n",
    "            input_a = torch.Tensor(input_a)\n",
    "            input_b = torch.Tensor(input_b)\n",
    "            linear_input_text = self.init_linear_text(input_b)\n",
    "            linear_input_other = self.init_linear_other_user(input_a)\n",
    "            linear_input_text = linear_input_text.view(linear_input_text.shape[0], 1, linear_input_text.shape[1])\n",
    "            linear_input_other = linear_input_other.view(linear_input_other.shape[0], 1, linear_input_other.shape[1])\n",
    "            attention_out_text, self.hidden_text = self.user_content_attention_text(linear_input_text, linear_input_text, linear_input_text)\n",
    "            attention_out_other, self.hidden_other = self.attention_other(linear_input_other, linear_input_other,linear_input_other)\n",
    "            attention_out_text = self.layernorm4(attention_out_text)\n",
    "            attention_out_other = self.layernorm5(attention_out_other)\n",
    "            concate = torch.cat((attention_out_text, attention_out_other), 1)\n",
    "\n",
    "        # mean pooling all the states\n",
    "        mean_pooling = torch.mean(concate, 1)\n",
    "\n",
    "        return mean_pooling\n",
    "    \n",
    "    def het_Bi_RNN(self, neighbor_id, node_type, post_emb_dict, user_emb_dict, news_emb_dict):\n",
    "        # Forward pass through initial hidden layer\n",
    "        new_id = []\n",
    "        if node_type == \"news\":\n",
    "            input_title = []\n",
    "            input_content = []\n",
    "            input_image = []\n",
    "            for i in neighbor_id:\n",
    "                if (\"news\", i) not in self.content_dict:\n",
    "                    input_title.append(news_emb_dict[i][0])\n",
    "                    input_content.append(news_emb_dict[i][1])\n",
    "                    input_image.append(news_emb_dict[i][2])\n",
    "                    new_id.append(i)\n",
    "            input_title = torch.Tensor(input_title)\n",
    "            input_image = torch.Tensor(input_image)\n",
    "            input_content = torch.Tensor(input_content)\n",
    "            linear_input_title = self.init_linear_text(input_title)\n",
    "            linear_input_content = self.init_linear_text(input_content)\n",
    "            linear_input_image = self.init_linear_image(input_image)\n",
    "            linear_input_title = linear_input_title.view(linear_input_title.shape[0], 1, linear_input_title.shape[1])\n",
    "            linear_input_content = linear_input_content.view(linear_input_content.shape[0], 1,\n",
    "                                                             linear_input_content.shape[1])\n",
    "            linear_input_image = linear_input_image.view(linear_input_image.shape[0], 1, linear_input_image.shape[1])\n",
    "            attention_out_title, self.hidden_text = self.news_title_LSTM_text(linear_input_title)\n",
    "            attention_out_content, self.hidden_text = self.news_content_LSTM_text(linear_input_content)\n",
    "            attention_out_image, self.hidden_image = self.LSTM_image(linear_input_image)\n",
    "            attention_out_title = self.layernorm1(attention_out_title)\n",
    "            attention_out_content = self.layernorm2(attention_out_content)\n",
    "            concate = torch.cat((attention_out_title, attention_out_content, attention_out_image), 1)\n",
    "        if node_type == \"post\":\n",
    "            input_a = []\n",
    "            for i in neighbor_id:\n",
    "                if (\"post\", i) not in self.content_dict:\n",
    "                    input_a.append(post_emb_dict[i][1])\n",
    "                    # input_b.append(post_emb_dict[i][1])\n",
    "                    new_id.append(i)\n",
    "            input_a = torch.Tensor(input_a)\n",
    "            # input_b = torch.Tensor(input_b)\n",
    "            linear_input_text = self.init_linear_text(input_a)\n",
    "            # linear_input_image = self.init_linear_image(input_b)\n",
    "            linear_input_text = linear_input_text.view(linear_input_text.shape[0], 1, linear_input_text.shape[1])\n",
    "            # linear_input_image = linear_input_image.view(linear_input_image.shape[0], 1, linear_input_image.shape[1])\n",
    "            attention_out_text, self.hidden_text = self.post_content_attention_text(linear_input_text)\n",
    "            attention_out_text = self.layernorm3(attention_out_text)\n",
    "            # LSTM_out_image, self.hidden_image = self.LSTM_image(linear_input_image)\n",
    "            concate = attention_out_text\n",
    "        if node_type == \"user\":\n",
    "            input_a = []\n",
    "            input_b = []\n",
    "            for i in neighbor_id:\n",
    "                if (\"user\", i) not in self.content_dict:\n",
    "                    input_a.append(user_emb_dict[i][0])\n",
    "                    input_b.append(user_emb_dict[i][1])\n",
    "                    new_id.append(i)\n",
    "            input_a = torch.Tensor(input_a)\n",
    "            input_b = torch.Tensor(input_b)\n",
    "            linear_input_text = self.init_linear_text(input_b)\n",
    "            linear_input_other = self.init_linear_other_user(input_a)\n",
    "            linear_input_text = linear_input_text.view(linear_input_text.shape[0], 1, linear_input_text.shape[1])\n",
    "            linear_input_other = linear_input_other.view(linear_input_other.shape[0], 1, linear_input_other.shape[1])\n",
    "            attention_out_text, self.hidden_text = self.user_content_attention_text(linear_input_text, linear_input_text, linear_input_text)\n",
    "            attention_out_other, self.hidden_other = self.attention_other(linear_input_other)\n",
    "            attention_out_text = self.layernorm4(attention_out_text)\n",
    "            attention_out_other = self.layernorm5(attention_out_other)\n",
    "            concate = torch.cat((attention_out_text, attention_out_other), 1)\n",
    "\n",
    "        # mean pooling all the states\n",
    "        mean_pooling = torch.mean(concate, 1)\n",
    "\n",
    "        return mean_pooling\n",
    "\n",
    "    # features: list of [(id)]\n",
    "    def transformer_aggregator(self, node, neighbor_ids, neighbor_node_types):\n",
    "        neighbor_content_embedings = self.het_Bi_RNN(neighbor_id, node_type, post_emb_dict, user_emb_dict, news_emb_dict)\n",
    "        decoder_input = neighbor_content_embedings.view(neighbor_content_embedings.shape[0], 1, neighbor_content_embedings.shape[1])\n",
    "        self_content_embedings = self.het_Bi_RNN([node.node_id], [node.node_type], post_emb_dict, user_emb_dict, news_emb_dict)\n",
    "        self_content_embedings = self_content_embedings.view(self_content_embedings.shape[0], 1, self_content_embedings.shape[1])\n",
    "        encoder_input = self.node_type_iput(neighbor_node_types) + self.positional_embedding(neighbor_content_embedings)\n",
    "        output = self.transformer(encoder_input, decoder_input) \n",
    "        return output\n",
    "        \n",
    "    def SameType_Agg_Bi_RNN(self, neighbor_id, node_type):\n",
    "        content_embedings = self.Bi_RNN(neighbor_id, node_type, post_emb_dict, user_emb_dict, news_emb_dict)\n",
    "        aft_rnn_dict = {}\n",
    "        for i in range(len(neighbor_id)):\n",
    "            aft_rnn_dict[neighbor_id[i]] = content_embedings[i]\n",
    "        if node_type == 'news':\n",
    "            linear_input = self.n_init_linear(content_embedings)\n",
    "            linear_input = linear_input.view(linear_input.shape[0], 1, linear_input.shape[1])\n",
    "            attention_out, hidden = self.n_attention(linear_input, linear_input, linear_input)\n",
    "            #LSTM_out = self.m6(LSTM_out)\n",
    "            last_state = self.n_linear(attention_out)\n",
    "            last_state = self.n_dropout(last_state)\n",
    "            mean_pooling = torch.mean(last_state, 0)\n",
    "            return mean_pooling, aft_rnn_dict\n",
    "        if node_type == 'post':\n",
    "            linear_input = self.p_init_linear(content_embedings)\n",
    "            # linear_input = self.p_init_dropout(linear_input)\n",
    "            linear_input = linear_input.view(linear_input.shape[0], 1, linear_input.shape[1])\n",
    "            attention_out, hidden = self.p_attention(linear_input, linear_input, linear_input)\n",
    "            #LSTM_out = self.m7(LSTM_out)\n",
    "            last_state = self.p_linear(attention_out)\n",
    "            last_state = self.p_dropout(last_state)\n",
    "            mean_pooling = torch.mean(last_state, 0)\n",
    "            return mean_pooling, aft_rnn_dict\n",
    "        if node_type == 'user':\n",
    "            linear_input = self.u_init_linear(content_embedings)\n",
    "            # linear_input = self.u_init_dropout(linear_input)\n",
    "            linear_input = linear_input.view(linear_input.shape[0], 1, linear_input.shape[1])\n",
    "            attention_out, hidden = self.u_attention(linear_input, linear_input, linear_input)\n",
    "            last_state = self.u_linear(attention_out)\n",
    "            last_state = self.u_dropout(last_state)\n",
    "            mean_pooling = torch.mean(last_state, 0)\n",
    "            return mean_pooling, aft_rnn_dict\n",
    "    \n",
    "    def transformer_agg(self, het_node, neighbor_order_n_p_u, neighbor_order_n, npu=200, n=5):  # heterogeneous neighbor aggregation\n",
    "        # attention module\n",
    "        c_agg_batch = self.Bi_RNN([het_node.node_id], het_node.node_type, post_emb_dict, user_emb_dict, news_emb_dict)\n",
    "        # news_neighbor_decoder = [item [1] for item in neighbor_order_n[:n]]\n",
    "        post_neighbor = [item[1] for item in neighbor_order_n_p_u[:npu] if item[0] == 'p']\n",
    "        user_neighbor = [item[1] for item in neighbor_order_n_p_u[:npu] if item[0] == 'u']\n",
    "        news_neighbor = [item[1] for item in neighbor_order_n_p_u[:npu] if item[0] == 'n']\n",
    "        # news_neighbor = [item [1] for item in neighbor_order_n_p_u if item[0] == 'n']\n",
    "        if news_neighbor:\n",
    "            n_agg_batch, n_aft_rnn_dict = self.SameType_Agg_Bi_RNN(news_neighbor, \"news\")\n",
    "        if user_neighbor:\n",
    "            u_agg_batch, u_aft_rnn_dict = self.SameType_Agg_Bi_RNN(user_neighbor, \"user\")\n",
    "        if post_neighbor:\n",
    "            p_agg_batch, p_aft_rnn_dict = self.SameType_Agg_Bi_RNN(post_neighbor, \"post\")\n",
    "        encoder_emb_input = []\n",
    "        decoder_emb_input = []\n",
    "        encoder_order_input = []\n",
    "        decoder_type_input = []\n",
    "        decoder_order_input = []\n",
    "        encoder_type_input = []\n",
    "        encoder_order_input.append(0)\n",
    "        encoder_emb_input.append(c_agg_batch[0])\n",
    "        encoder_type_input.append(0)\n",
    "        for i, type_id in enumerate(neighbor_order_n_p_u[:npu]):\n",
    "            if type_id[0] == 'p' and post_neighbor:\n",
    "                if type_id[1] not in list(p_aft_rnn_dict.keys()):\n",
    "                    #print(\"no emb!\")\n",
    "                    continue\n",
    "                encoder_emb_input.append(torch.Tensor(p_aft_rnn_dict[type_id[1]]))\n",
    "                encoder_type_input.append(1)\n",
    "            elif type_id[0] == 'u' and user_neighbor:\n",
    "                if type_id[1] not in list(u_aft_rnn_dict.keys()):\n",
    "                    #print(\"no emb!\")\n",
    "                    continue\n",
    "                encoder_emb_input.append(torch.Tensor(u_aft_rnn_dict[type_id[1]]))\n",
    "                encoder_type_input.append(2)\n",
    "            elif type_id[0] == 'n' and news_neighbor:\n",
    "                if type_id[1] not in list(n_aft_rnn_dict.keys()):\n",
    "                    #print(\"no emb!\")\n",
    "                    continue\n",
    "                encoder_emb_input.append(torch.Tensor(n_aft_rnn_dict[type_id[1]]))\n",
    "                encoder_type_input.append(0)\n",
    "            encoder_order_input.append(i+1)\n",
    "        #encoder_emb_input = torch.Tensor(encoder_emb_input)\n",
    "        encoder_type_input = torch.LongTensor(encoder_type_input)\n",
    "        encoder_order_input = torch.LongTensor(encoder_order_input)\n",
    "        decoder_emb_input.append(c_agg_batch[0])\n",
    "        decoder_type_input.append(0)\n",
    "        #print(neighbor_order_n)\n",
    "        #for (i, type_id) in enumerate(news_neighbor):\n",
    "        #    decoder_emb_input.append(torch.Tensor(n_aft_rnn_dict[type_id]))\n",
    "        #    decoder_order_input.append(i+1)\n",
    "        #    decoder_type_input.append(0)\n",
    "        for (i, type_id) in enumerate(news_neighbor):\n",
    "            decoder_emb_input.append(torch.Tensor(n_aft_rnn_dict[type_id]))\n",
    "            decoder_order_input.append(i+1)\n",
    "            decoder_type_input.append(0)\n",
    "        # decoder_order_input = torch.LongTensor(decoder_order_input)\n",
    "        decoder_type_input = torch.LongTensor(decoder_type_input)\n",
    "        encoder_emb_input = torch.stack(encoder_emb_input)\n",
    "        encoder_emb_input = encoder_emb_input.view(encoder_emb_input.shape[0], 1, encoder_emb_input.shape[1])\n",
    "        decoder_emb_input = torch.stack(decoder_emb_input)\n",
    "        decoder_emb_input = decoder_emb_input.view(decoder_emb_input.shape[0], 1, decoder_emb_input.shape[1])\n",
    "        encoder_emb_input += self.type_encoder(encoder_type_input).view(encoder_emb_input.shape[0], 1, encoder_emb_input.shape[2])\n",
    "        encoder_emb_input += self.pos_encoder(encoder_emb_input)\n",
    "        decoder_emb_input += self.pos_encoder(decoder_emb_input)\n",
    "        decoder_emb_input += self.type_encoder(decoder_type_input).view(decoder_emb_input.shape[0], 1, decoder_emb_input.shape[2])\n",
    "        final_representation = self.transformer(encoder_emb_input, decoder_emb_input)\n",
    "        return final_representation\n",
    "    \n",
    "    def node_het_agg(self, het_node):  # heterogeneous neighbor aggregation\n",
    "\n",
    "        # attention module\n",
    "        c_agg_batch = self.Bi_RNN([het_node.node_id], het_node.node_type, post_emb_dict, user_emb_dict, news_emb_dict)\n",
    "        n_agg_batch, n_aft_rnn_dict = self.SameType_Agg_Bi_RNN(het_node.neighbors_news, \"news\")\n",
    "        u_agg_batch, u_aft_rnn_dict = self.SameType_Agg_Bi_RNN(het_node.neighbors_user, \"user\")\n",
    "        p_agg_batch, p_aft_rnn_dict = self.SameType_Agg_Bi_RNN(het_node.neighbors_post, \"post\")\n",
    "        if self.use_gcn:\n",
    "            gcn2_user, gcn2_post, gcn2_news = self.GCN_net(u_aft_rnn_dict, p_aft_rnn_dict, n_aft_rnn_dict)\n",
    "\n",
    "        c_agg_batch_2 = torch.cat((c_agg_batch, c_agg_batch), 1).view(len(c_agg_batch), self.embed_d * 2)\n",
    "        n_agg_batch_2 = torch.cat((c_agg_batch, n_agg_batch), 1).view(len(c_agg_batch), self.embed_d * 2)\n",
    "        u_agg_batch_2 = torch.cat((c_agg_batch, u_agg_batch), 1).view(len(c_agg_batch), self.embed_d * 2)\n",
    "        p_agg_batch_2 = torch.cat((c_agg_batch, p_agg_batch), 1).view(len(c_agg_batch), self.embed_d * 2)\n",
    "        if self.use_gcn:\n",
    "            u_agg_batch_2 = torch.cat((gcn2_user, u_agg_batch_2), 0)\n",
    "            u_agg_batch_2 = torch.mean(u_agg_batch_2, 0, keepdims=True)\n",
    "\n",
    "            p_agg_batch_2 = torch.cat((gcn2_post, p_agg_batch_2), 0)\n",
    "            p_agg_batch_2 = torch.mean(p_agg_batch_2, 0, keepdims=True)\n",
    "\n",
    "            n_agg_batch_2 = torch.cat((gcn2_news, n_agg_batch_2), 0)\n",
    "            n_agg_batch_2 = torch.mean(n_agg_batch_2, 0, keepdims=True)\n",
    "\n",
    "        # compute weights\n",
    "        concate_embed = torch.cat((c_agg_batch_2, u_agg_batch_2, p_agg_batch_2, n_agg_batch_2), 1).view(\n",
    "            len(c_agg_batch), 4,\n",
    "            self.embed_d * 2)\n",
    "        if het_node.node_type == \"user\":\n",
    "            atten_w = self.act(torch.bmm(concate_embed, self.u_neigh_att.unsqueeze(0).expand(len(c_agg_batch),\n",
    "                                                                                             *self.u_neigh_att.size())))\n",
    "        elif het_node.node_type == \"post\":\n",
    "            atten_w = self.act(torch.bmm(concate_embed, self.p_neigh_att.unsqueeze(0).expand(len(c_agg_batch),\n",
    "                                                                                             *self.p_neigh_att.size())))\n",
    "        else:\n",
    "            atten_w = self.act(torch.bmm(concate_embed, self.n_neigh_att.unsqueeze(0).expand(len(c_agg_batch),\n",
    "                                                                                             *self.n_neigh_att.size())))\n",
    "        atten_w = self.softmax(atten_w).view(len(c_agg_batch), 1, 4)\n",
    "        # print(atten_w)\n",
    "\n",
    "        # weighted combination\n",
    "        concate_embed = torch.cat((c_agg_batch, u_agg_batch, p_agg_batch, n_agg_batch), 1).view(len(c_agg_batch), 4,\n",
    "                                                                                                self.embed_d)\n",
    "        weight_agg_batch = torch.bmm(atten_w, concate_embed).view(len(c_agg_batch), self.embed_d)\n",
    "\n",
    "        return weight_agg_batch\n",
    "\n",
    "    def output(self, c_embed_batch):\n",
    "        batch_size = 1\n",
    "        # make c_embed 3D tensor. Batch_size * 1 * embed_d\n",
    "        #print(c_embed_batch.shape)\n",
    "        c_embed = c_embed_batch[0, 0, :]\n",
    "        c_embed = c_embed.view(batch_size, 1, self.out_embed_d)\n",
    "        c_embed = self.out_dropout(c_embed)\n",
    "        c_embed_out = self.out_linear(c_embed)\n",
    "        # c_embed_out = self.out_final(c_embed)\n",
    "        predictions = self.output_act(c_embed_out)  # log(1/(1+exp(-x)))    sigmoid = 1/(1+exp(-x))\n",
    "        return predictions\n",
    "\n",
    "    def forward(self, x, neighbor_order_n_p_u, neighbor_order_n):\n",
    "        x = self.transformer_agg(x, neighbor_order_n_p_u, neighbor_order_n, npu=self.npu)\n",
    "        x = self.output(c_embed_batch=x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def BCELoss(predictions, true_label):\n",
    "    loss = nn.BCELoss()\n",
    "    predictions = predictions.view(1)\n",
    "    tensor_label = torch.FloatTensor(np.array([true_label]))\n",
    "    loss_sum = loss(predictions, tensor_label)\n",
    "    return loss_sum\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, save_path, epoch, val_acc):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'val_acc': val_acc\n",
    "    }, save_path)\n",
    "\n",
    "\n",
    "def load_checkpoint(model, optimizer, load_path):\n",
    "    checkpoint = torch.load(load_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    val_acc = checkpoint['val_acc']\n",
    "    return model, optimizer, epoch, val_acc\n",
    "\n",
    "\n",
    "def train_test(data_real, data_fake, test_size):\n",
    "    y_real = range(len(data_real))\n",
    "    y_fake = range(len(data_fake))\n",
    "    X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(data_real, y_real, test_size=test_size, random_state=42)\n",
    "    X_train_fake, X_test_fake, y_train_fake, y_test_fake = train_test_split(data_fake, y_fake, test_size=test_size, random_state=42)\n",
    "    np.savetxt('/model/data_splits/PolitiFact/train_index_real.txt', y_train_real)\n",
    "    np.savetxt('/model/data_splits/PolitiFact/test_index_real.txt', y_test_real)\n",
    "    np.savetxt('/model/data_splits/PolitiFact/train_index_fake.txt', y_train_fake)\n",
    "    np.savetxt('/model/data_splits/PolitiFact/test_index_fake.txt', y_test_fake)\n",
    "    return X_train_real, X_test_real, X_train_fake, X_test_fake\n",
    "\n",
    "\n",
    "\n",
    "def load_train_test(data_real, data_fake, test_index_path_real='/model/data_splits/PolitiFact/test_index_real.txt', test_index_path_fake = '/model/data_splits/PolitiFact/test_index_fake.txt'):\n",
    "    a = np.loadtxt(test_index_path_real)\n",
    "    a = a.astype('int32')\n",
    "    b = np.loadtxt(test_index_path_fake)\n",
    "    b = b.astype('int32')\n",
    "    test_set_real = []\n",
    "    train_set_real = []\n",
    "    for i in range(len(data_real)):\n",
    "        if i in a:\n",
    "            test_set_real.append(data_real[i])\n",
    "        else:\n",
    "            train_set_real.append(data_real[i])\n",
    "    test_set_fake = []\n",
    "    train_set_fake = []\n",
    "    for j in range(len(data_fake)):\n",
    "        if j in b:\n",
    "            test_set_fake.append(data_fake[j])\n",
    "        else:\n",
    "            train_set_fake.append(data_fake[j])\n",
    "    return train_set_real, test_set_real, train_set_fake, test_set_fake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "776abf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/data/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass shuffle=True, random_state=1 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "# split test set first\n",
    "if path.exists('/model/data_splits/PolitiFact/test_index_real.txt'):\n",
    "    X_train_real, X_test_real, X_train_fake, X_test_fake = load_train_test(news_nodes_real, news_nodes_fake)\n",
    "else:\n",
    "    X_train_real, X_test_real, X_train_fake, X_test_fake = train_test(news_nodes_real, news_nodes_fake, 0.1)\n",
    "\n",
    "import time\n",
    "\n",
    "# Shuffle the order in post nodes\n",
    "train_val = X_train_real + X_train_fake\n",
    "test_set = X_test_real + X_test_fake\n",
    "np.random.shuffle(train_val)\n",
    "np.random.shuffle(test_set)\n",
    "\n",
    "# K-fold validation index\n",
    "train_index = []\n",
    "val_index = []\n",
    "num_splits = 9\n",
    "kfold = KFold(num_splits, True, 1)\n",
    "for train, val in kfold.split(train_val):\n",
    "    train_index.append(train)\n",
    "    val_index.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5e38be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Start for fold 1\n",
      "total number of neighbors:  16\n",
      "init time:  0.150726318359375\n",
      "Epoch: 1\n",
      "Fold: 1, Epoch: 1, step:   100, loss: 0.9056, acc: 0.5100\n",
      "Fold: 1, Epoch: 1, step:   200, loss: 0.6683, acc: 0.7200\n",
      "Fold: 1, Epoch: 1, step:   300, loss: 0.6290, acc: 0.6700\n",
      "Fold: 1, Epoch: 1, step:   400, loss: 0.6250, acc: 0.7100\n",
      "Fold: 1, Epoch: 1, step:   500, loss: 0.6640, acc: 0.7300\n",
      "Fold: 1, Epoch: 1, step:   600, loss: 0.3659, acc: 0.8100\n",
      "Validation loss: 0.3212, Validation accuracy: 0.8481\n",
      "Real Precision: 0.7838, Real Recall: 0.8788, Real F1: 0.8286\n",
      "Fake Precision: 0.9048, Fake Recall: 0.8261, Fake F1: 0.8636\n",
      "Test loss: 0.3530, Test accuracy: 0.8750\n",
      "Real Precision: 0.8974, Real Recall: 0.8537, Real F1: 0.8750\n",
      "Fake Precision: 0.8537, Fake Recall: 0.8974, Fake F1: 0.8750\n",
      "Update model at epoch: 1\n",
      "Epoch: 2\n",
      "Fold: 1, Epoch: 2, step:   100, loss: 0.4258, acc: 0.7700\n",
      "Fold: 1, Epoch: 2, step:   200, loss: 0.3142, acc: 0.9000\n",
      "Fold: 1, Epoch: 2, step:   300, loss: 0.4046, acc: 0.8700\n",
      "Fold: 1, Epoch: 2, step:   400, loss: 0.2905, acc: 0.9000\n",
      "Fold: 1, Epoch: 2, step:   500, loss: 0.2009, acc: 0.9400\n",
      "Fold: 1, Epoch: 2, step:   600, loss: 0.3891, acc: 0.8300\n",
      "Validation loss: 0.3369, Validation accuracy: 0.8861\n",
      "Real Precision: 0.9000, Real Recall: 0.8182, Real F1: 0.8571\n",
      "Fake Precision: 0.8776, Fake Recall: 0.9348, Fake F1: 0.9053\n",
      "Test loss: 0.4528, Test accuracy: 0.8125\n",
      "Real Precision: 0.8824, Real Recall: 0.7317, Real F1: 0.8000\n",
      "Fake Precision: 0.7609, Fake Recall: 0.8974, Fake F1: 0.8235\n",
      "Update model at epoch: 2\n",
      "Epoch: 3\n",
      "Fold: 1, Epoch: 3, step:   100, loss: 0.2919, acc: 0.8300\n",
      "Fold: 1, Epoch: 3, step:   200, loss: 0.2679, acc: 0.9100\n",
      "Fold: 1, Epoch: 3, step:   300, loss: 0.1672, acc: 0.9200\n",
      "Fold: 1, Epoch: 3, step:   400, loss: 0.3276, acc: 0.9200\n",
      "Fold: 1, Epoch: 3, step:   500, loss: 0.2708, acc: 0.9200\n",
      "Fold: 1, Epoch: 3, step:   600, loss: 0.3156, acc: 0.9000\n",
      "Validation loss: 0.3487, Validation accuracy: 0.8861\n",
      "Real Precision: 0.8333, Real Recall: 0.9091, Real F1: 0.8696\n",
      "Fake Precision: 0.9302, Fake Recall: 0.8696, Fake F1: 0.8989\n",
      "Test loss: 0.3536, Test accuracy: 0.8875\n",
      "Real Precision: 0.9000, Real Recall: 0.8780, Real F1: 0.8889\n",
      "Fake Precision: 0.8750, Fake Recall: 0.8974, Fake F1: 0.8861\n",
      "Update model at epoch: 3\n",
      "Epoch: 4\n",
      "Fold: 1, Epoch: 4, step:   100, loss: 0.2729, acc: 0.8800\n",
      "Fold: 1, Epoch: 4, step:   200, loss: 0.2879, acc: 0.8800\n",
      "Fold: 1, Epoch: 4, step:   300, loss: 0.2015, acc: 0.9100\n",
      "Fold: 1, Epoch: 4, step:   400, loss: 0.1585, acc: 0.9300\n",
      "Fold: 1, Epoch: 4, step:   500, loss: 0.1437, acc: 0.9600\n",
      "Fold: 1, Epoch: 4, step:   600, loss: 0.2564, acc: 0.9300\n",
      "Validation loss: 0.3878, Validation accuracy: 0.8987\n",
      "Real Precision: 0.8571, Real Recall: 0.9091, Real F1: 0.8824\n",
      "Fake Precision: 0.9318, Fake Recall: 0.8913, Fake F1: 0.9111\n",
      "Test loss: 0.3320, Test accuracy: 0.8750\n",
      "Real Precision: 0.8780, Real Recall: 0.8780, Real F1: 0.8780\n",
      "Fake Precision: 0.8718, Fake Recall: 0.8718, Fake F1: 0.8718\n",
      "Update model at epoch: 4\n",
      "Epoch: 5\n",
      "Fold: 1, Epoch: 5, step:   100, loss: 0.1615, acc: 0.9400\n",
      "Fold: 1, Epoch: 5, step:   200, loss: 0.2149, acc: 0.9200\n",
      "Fold: 1, Epoch: 5, step:   300, loss: 0.1884, acc: 0.9200\n",
      "Fold: 1, Epoch: 5, step:   400, loss: 0.1820, acc: 0.9400\n",
      "Fold: 1, Epoch: 5, step:   500, loss: 0.1477, acc: 0.9600\n",
      "Fold: 1, Epoch: 5, step:   600, loss: 0.1670, acc: 0.9300\n",
      "Validation loss: 0.5420, Validation accuracy: 0.8228\n",
      "Real Precision: 0.7317, Real Recall: 0.9091, Real F1: 0.8108\n",
      "Fake Precision: 0.9211, Fake Recall: 0.7609, Fake F1: 0.8333\n",
      "Test loss: 0.3961, Test accuracy: 0.9000\n",
      "Real Precision: 0.8511, Real Recall: 0.9756, Real F1: 0.9091\n",
      "Fake Precision: 0.9697, Fake Recall: 0.8205, Fake F1: 0.8889\n",
      "Epoch: 6\n",
      "Fold: 1, Epoch: 6, step:   100, loss: 0.1046, acc: 0.9700\n",
      "Fold: 1, Epoch: 6, step:   200, loss: 0.1561, acc: 0.9300\n",
      "Fold: 1, Epoch: 6, step:   300, loss: 0.1999, acc: 0.9200\n",
      "Fold: 1, Epoch: 6, step:   400, loss: 0.2559, acc: 0.9100\n",
      "Fold: 1, Epoch: 6, step:   500, loss: 0.2519, acc: 0.9200\n",
      "Fold: 1, Epoch: 6, step:   600, loss: 0.1687, acc: 0.9300\n",
      "Validation loss: 0.3935, Validation accuracy: 0.8987\n",
      "Real Precision: 0.8571, Real Recall: 0.9091, Real F1: 0.8824\n",
      "Fake Precision: 0.9318, Fake Recall: 0.8913, Fake F1: 0.9111\n",
      "Test loss: 0.3485, Test accuracy: 0.8750\n",
      "Real Precision: 0.8780, Real Recall: 0.8780, Real F1: 0.8780\n",
      "Fake Precision: 0.8718, Fake Recall: 0.8718, Fake F1: 0.8718\n",
      "Update model at epoch: 6\n",
      "Epoch: 7\n",
      "Fold: 1, Epoch: 7, step:   100, loss: 0.2303, acc: 0.9000\n",
      "Fold: 1, Epoch: 7, step:   200, loss: 0.1874, acc: 0.9300\n",
      "Fold: 1, Epoch: 7, step:   300, loss: 0.0910, acc: 0.9700\n",
      "Fold: 1, Epoch: 7, step:   400, loss: 0.1095, acc: 0.9500\n",
      "Fold: 1, Epoch: 7, step:   500, loss: 0.1762, acc: 0.9300\n",
      "Fold: 1, Epoch: 7, step:   600, loss: 0.1530, acc: 0.9400\n",
      "Validation loss: 0.4042, Validation accuracy: 0.8608\n",
      "Real Precision: 0.7895, Real Recall: 0.9091, Real F1: 0.8451\n",
      "Fake Precision: 0.9268, Fake Recall: 0.8261, Fake F1: 0.8736\n",
      "Test loss: 0.3544, Test accuracy: 0.8875\n",
      "Real Precision: 0.8810, Real Recall: 0.9024, Real F1: 0.8916\n",
      "Fake Precision: 0.8947, Fake Recall: 0.8718, Fake F1: 0.8831\n",
      "Epoch: 8\n",
      "Fold: 1, Epoch: 8, step:   100, loss: 0.0921, acc: 0.9800\n",
      "Fold: 1, Epoch: 8, step:   200, loss: 0.1180, acc: 0.9400\n",
      "Fold: 1, Epoch: 8, step:   300, loss: 0.1505, acc: 0.9600\n",
      "Fold: 1, Epoch: 8, step:   400, loss: 0.1447, acc: 0.9600\n",
      "Fold: 1, Epoch: 8, step:   500, loss: 0.1375, acc: 0.9400\n",
      "Fold: 1, Epoch: 8, step:   600, loss: 0.1813, acc: 0.9300\n",
      "Validation loss: 0.4053, Validation accuracy: 0.8608\n",
      "Real Precision: 0.7895, Real Recall: 0.9091, Real F1: 0.8451\n",
      "Fake Precision: 0.9268, Fake Recall: 0.8261, Fake F1: 0.8736\n",
      "Test loss: 0.3624, Test accuracy: 0.8875\n",
      "Real Precision: 0.8810, Real Recall: 0.9024, Real F1: 0.8916\n",
      "Fake Precision: 0.8947, Fake Recall: 0.8718, Fake F1: 0.8831\n",
      "Epoch: 9\n",
      "Fold: 1, Epoch: 9, step:   100, loss: 0.1635, acc: 0.9600\n",
      "Fold: 1, Epoch: 9, step:   200, loss: 0.1348, acc: 0.9300\n",
      "Fold: 1, Epoch: 9, step:   300, loss: 0.1469, acc: 0.9500\n",
      "Fold: 1, Epoch: 9, step:   400, loss: 0.1565, acc: 0.9400\n",
      "Fold: 1, Epoch: 9, step:   500, loss: 0.1213, acc: 0.9600\n",
      "Fold: 1, Epoch: 9, step:   600, loss: 0.1069, acc: 0.9700\n",
      "Validation loss: 0.4120, Validation accuracy: 0.8481\n",
      "Real Precision: 0.7692, Real Recall: 0.9091, Real F1: 0.8333\n",
      "Fake Precision: 0.9250, Fake Recall: 0.8043, Fake F1: 0.8605\n",
      "Test loss: 0.3650, Test accuracy: 0.8875\n",
      "Real Precision: 0.8810, Real Recall: 0.9024, Real F1: 0.8916\n",
      "Fake Precision: 0.8947, Fake Recall: 0.8718, Fake F1: 0.8831\n",
      "Epoch: 10\n",
      "Fold: 1, Epoch: 10, step:   100, loss: 0.1129, acc: 0.9800\n",
      "Fold: 1, Epoch: 10, step:   200, loss: 0.0822, acc: 0.9700\n",
      "Fold: 1, Epoch: 10, step:   300, loss: 0.3006, acc: 0.8900\n",
      "Fold: 1, Epoch: 10, step:   400, loss: 0.0831, acc: 0.9800\n",
      "Fold: 1, Epoch: 10, step:   500, loss: 0.1002, acc: 0.9700\n",
      "Fold: 1, Epoch: 10, step:   600, loss: 0.1437, acc: 0.9300\n",
      "Validation loss: 0.4241, Validation accuracy: 0.8481\n",
      "Real Precision: 0.7692, Real Recall: 0.9091, Real F1: 0.8333\n",
      "Fake Precision: 0.9250, Fake Recall: 0.8043, Fake F1: 0.8605\n",
      "Test loss: 0.3691, Test accuracy: 0.8875\n",
      "Real Precision: 0.8810, Real Recall: 0.9024, Real F1: 0.8916\n",
      "Fake Precision: 0.8947, Fake Recall: 0.8718, Fake F1: 0.8831\n",
      "Epoch: 11\n",
      "Fold: 1, Epoch: 11, step:   100, loss: 0.0721, acc: 0.9700\n",
      "Fold: 1, Epoch: 11, step:   200, loss: 0.2016, acc: 0.9400\n",
      "Fold: 1, Epoch: 11, step:   300, loss: 0.1681, acc: 0.9400\n",
      "Fold: 1, Epoch: 11, step:   400, loss: 0.1025, acc: 0.9600\n",
      "Fold: 1, Epoch: 11, step:   500, loss: 0.1567, acc: 0.9500\n",
      "Fold: 1, Epoch: 11, step:   600, loss: 0.1400, acc: 0.9200\n",
      "Validation loss: 0.4394, Validation accuracy: 0.8481\n",
      "Real Precision: 0.7692, Real Recall: 0.9091, Real F1: 0.8333\n",
      "Fake Precision: 0.9250, Fake Recall: 0.8043, Fake F1: 0.8605\n",
      "Test loss: 0.3683, Test accuracy: 0.9000\n",
      "Real Precision: 0.8837, Real Recall: 0.9268, Real F1: 0.9048\n",
      "Fake Precision: 0.9189, Fake Recall: 0.8718, Fake F1: 0.8947\n",
      "Average time for a epoch:  25.538902854919435 num of neighbor:  16\n",
      "Finish training\n",
      "==============================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize parameters\n",
    "lr = 0.001\n",
    "num_epoch = 40\n",
    "num_folds = 1\n",
    "batch_size = 4\n",
    "PATH = 'model/best_models/PolitiFact'\n",
    "npus = [16,]  # 2, 4, 8, 16, 32, 64, 128, 256, 512\n",
    "# cur_PATH = PATH + '9441.tar'\n",
    "print('Start training')\n",
    "for npu in npus:\n",
    "    for fold in range(num_folds):\n",
    "        t0 = time.time()\n",
    "        print(\"Start for fold\", fold + 1)\n",
    "        print(\"total number of neighbors: \", npu)\n",
    "        best_val = 0\n",
    "        running_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        test_loss = 0.0\n",
    "        best_epoch = 0\n",
    "        net = Het_GNN(input_dim=[768, 512, 3, 29], ini_hidden_dim=[200, 200, 200, 200], hidden_dim=100,\n",
    "                      n_hidden_dim=200, n_ini_hidden_dim=128, n_output_dim=150,\n",
    "                      u_hidden_dim=200, u_ini_hidden_dim=128, u_output_dim=150,\n",
    "                      p_hidden_dim=200, p_ini_hidden_dim=128, p_output_dim=150,\n",
    "                      out_embed_d=208, GCN_out1=550, d_model=208, attn_heads=8, use_gcn=True, enc_layers=1)\n",
    "        net.init_weights()\n",
    "        # print(net)\n",
    "        # Set up optimizer and scheduler\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "        scheduler = StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "        t1 = time.time()\n",
    "        print(\"init time: \", t1-t0)\n",
    "        # net, optimizer, epoch, best_val = load_checkpoint(net, optimizer, cur_PATH)\n",
    "        times = []\n",
    "        for epoch in range(num_epoch):\n",
    "            #print('Epoch:', epoch + 1)\n",
    "            t_current_start = time.time()\n",
    "            print('Epoch:', epoch + 1)\n",
    "            m = 0.0\n",
    "            train_loss = 0.0\n",
    "            c = 0.0\n",
    "            running_loss = 0.0\n",
    "            v = 0.0\n",
    "            val_loss = 0.0\n",
    "            t = 0.0\n",
    "            test_loss = 0.0\n",
    "            real_count = 0.0\n",
    "            fake_count = 0.0\n",
    "            real_true = 0.0\n",
    "            fake_true = 0.0\n",
    "            # generate train and test set for current epoch\n",
    "            train_set = []\n",
    "            val_set = []\n",
    "            for t_index in train_index[fold]:\n",
    "                train_set.append(train_val[t_index])\n",
    "            for v_index in val_index[fold]:\n",
    "                val_set.append(train_val[v_index])\n",
    "            random.shuffle(train_set)\n",
    "            net.train()\n",
    "            for i in range(len(train_set)):\n",
    "                optimizer.zero_grad()\n",
    "                output = net(train_set[i], neighbor_dict[0][train_set[i].node_id], neighbor_dict[1][train_set[i].node_id])\n",
    "                if (output.item() >= 0.5 and train_set[i].label == 1) or (output.item() < 0.5 and train_set[i].label == 0):\n",
    "                    c += 1\n",
    "                cur_loss = BCELoss(predictions=output, true_label=train_set[i].label)\n",
    "                running_loss += cur_loss.item()\n",
    "                if i % 100 == 99:  # print every 100 mini-batches\n",
    "                    print('Fold: %d, Epoch: %d, step: %5d, loss: %.4f, acc: %.4f' %\n",
    "                          (fold + 1, epoch + 1, i + 1, running_loss / 100, c / 100))\n",
    "                    running_loss = 0.0\n",
    "                    c = 0.0\n",
    "                if i % batch_size == 0:\n",
    "                    loss = Variable(torch.zeros(1), requires_grad=True)\n",
    "                loss = loss + cur_loss\n",
    "                if i % batch_size == (batch_size - 1):\n",
    "                    loss = loss / batch_size\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            net.eval()\n",
    "            for j in range(len(val_set)):\n",
    "                output = net(val_set[j], neighbor_dict[0][val_set[j].node_id], neighbor_dict[1][val_set[j].node_id])\n",
    "                if val_set[j].label == 1:\n",
    "                    real_count += 1\n",
    "                    if output.item() >= 0.5:\n",
    "                        real_true += 1\n",
    "                else:\n",
    "                    fake_count += 1\n",
    "                    if output.item() < 0.5:\n",
    "                        fake_true += 1\n",
    "                if (output.item() >= 0.5 and val_set[j].label == 1) or (output.item() < 0.5 and val_set[j].label == 0):\n",
    "                    v += 1\n",
    "                vloss = BCELoss(predictions=output, true_label=val_set[j].label)\n",
    "                val_loss += vloss.item()\n",
    "            val_acc = v / len(val_set)\n",
    "            #val_acc_set.append(val_acc)\n",
    "            #val_loss_set.append(val_loss / len(val_set))\n",
    "            real_precision = real_true / (real_true + fake_count - fake_true)\n",
    "            fake_precision = fake_true / (fake_true + real_count - real_true)\n",
    "            real_recall = real_true / real_count\n",
    "            fake_recall = fake_true / fake_count\n",
    "            real_f1 = 2 * real_precision * real_recall / (real_precision + real_recall)\n",
    "            fake_f1 = 2 * fake_precision * fake_recall / (fake_precision + fake_recall)\n",
    "            print('Validation loss: %.4f, Validation accuracy: %.4f' % (val_loss / len(val_set), val_acc))\n",
    "            print('Real Precision: %.4f, Real Recall: %.4f, Real F1: %.4f' % (real_precision, real_recall, real_f1))\n",
    "            print('Fake Precision: %.4f, Fake Recall: %.4f, Fake F1: %.4f' % (fake_precision, fake_recall, fake_f1))\n",
    "            t = 0.0\n",
    "            test_loss = 0.0\n",
    "            real_count = 0.0\n",
    "            fake_count = 0.0\n",
    "            real_true = 0.0\n",
    "            fake_true = 0.0\n",
    "            for k in range(len(test_set)):\n",
    "                output = 0.0\n",
    "                avg_tloss = 0.0\n",
    "                for fold in range(num_folds):\n",
    "                    result = net(test_set[k], neighbor_dict[0][test_set[k].node_id], neighbor_dict[1][test_set[k].node_id])\n",
    "                    output += result.item()\n",
    "                    tloss = BCELoss(predictions=result, true_label=test_set[k].label)\n",
    "                    avg_tloss += tloss.item()\n",
    "                output /= num_folds\n",
    "                avg_tloss /= num_folds\n",
    "                test_loss += avg_tloss\n",
    "                if (output >= 0.5 and test_set[k].label == 1) or (output < 0.5 and test_set[k].label == 0):\n",
    "                    t += 1\n",
    "                if test_set[k].label == 1:\n",
    "                    real_count += 1\n",
    "                    if output >= 0.5:\n",
    "                        real_true += 1\n",
    "                else:\n",
    "                    fake_count += 1\n",
    "                    if output < 0.5:\n",
    "                        fake_true += 1\n",
    "\n",
    "            real_precision = real_true / (real_true + fake_count - fake_true)\n",
    "            fake_precision = fake_true / (fake_true + real_count - real_true)\n",
    "            real_recall = real_true / real_count\n",
    "            fake_recall = fake_true / fake_count\n",
    "            real_f1 = 2 * real_precision * real_recall / (real_precision + real_recall)\n",
    "            fake_f1 = 2 * fake_precision * fake_recall / (fake_precision + fake_recall)\n",
    "            print('Test loss: %.4f, Test accuracy: %.4f' % (test_loss / len(test_set), t / len(test_set)))\n",
    "            print('Real Precision: %.4f, Real Recall: %.4f, Real F1: %.4f' % (real_precision, real_recall, real_f1))\n",
    "            print('Fake Precision: %.4f, Fake Recall: %.4f, Fake F1: %.4f' % (fake_precision, fake_recall, fake_f1))\n",
    "            if val_acc >= best_val:\n",
    "                print('Update model at epoch:', epoch + 1)\n",
    "                cur_PATH = PATH + 'best_model' + '_' + str(npu) + '.tar'\n",
    "                save_checkpoint(net, optimizer, cur_PATH, epoch + 1, val_acc)\n",
    "                best_val = val_acc\n",
    "                best_epoch = epoch\n",
    "            scheduler.step()\n",
    "            if epoch - best_epoch >= 5:\n",
    "                break\n",
    "            t_current_end = time.time()\n",
    "            times += [t_current_end-t_current_start]\n",
    "        print(\"Average time for a epoch: \", sum(times) / len(times), \"num of neighbor: \", npu)\n",
    "        print('Finish training')\n",
    "\n",
    "    print('==============================================================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7bf5be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057fe89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init net and optimizer skeletons\n",
    "# best_models = []\n",
    "# num_folds = 1\n",
    "# net = Het_GNN(input_dim=[768, 512, 3, 29], ini_hidden_dim=[200, 200, 200, 200], hidden_dim=100,\n",
    "#                   n_hidden_dim=200, n_ini_hidden_dim=128, n_output_dim=150,\n",
    "#                   u_hidden_dim=200, u_ini_hidden_dim=128, u_output_dim=150,\n",
    "#                   p_hidden_dim=200, p_ini_hidden_dim=128, p_output_dim=150,\n",
    "#                   out_embed_d=208, GCN_out1=550, d_model=208, attn_heads=8, use_gcn=True, enc_layers=1, npu=npu)\n",
    "# net.init_weights()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "# for count in range(num_folds):\n",
    "#     cur_PATH = PATH + 'best_model' + '_' + str(count) + '.tar'\n",
    "#     net, optimizer, epoch, best_val = load_checkpoint(net, optimizer, cur_PATH)\n",
    "#     print(best_val)\n",
    "#     net.eval()\n",
    "#     best_models.append(net)\n",
    "\n",
    "# t = 0.0\n",
    "# test_loss = 0.0\n",
    "# real_count = 0.0\n",
    "# fake_count = 0.0\n",
    "# real_true = 0.0     \n",
    "# fake_true = 0.0\n",
    "# for k in range(len(test_set)):\n",
    "#     output = 0.0\n",
    "#     avg_tloss = 0.0\n",
    "#     for fold in range(num_folds):\n",
    "#         result = best_models[fold](test_set[k], neighbor_dict[0][test_set[k].node_id], neighbor_dict[1][test_set[k].node_id])\n",
    "#         output += result.item()\n",
    "#         tloss = BCELoss(predictions=result, true_label=test_set[k].label)\n",
    "#         avg_tloss += tloss.item()\n",
    "#     output /= num_folds\n",
    "#     avg_tloss /= num_folds\n",
    "#     test_loss += avg_tloss\n",
    "#     if (output >= 0.5 and test_set[k].label == 1) or (output < 0.5 and test_set[k].label == 0):\n",
    "#         t += 1\n",
    "#     if test_set[k].label == 1:\n",
    "#         real_count += 1\n",
    "#         if output >= 0.5:\n",
    "#             real_true += 1\n",
    "#     else:\n",
    "#         fake_count += 1\n",
    "#         if output < 0.5:\n",
    "#             fake_true += 1\n",
    "\n",
    "# real_precision = real_true / (real_true + fake_count - fake_true)\n",
    "# fake_precision = fake_true / (fake_true + real_count - real_true)\n",
    "# real_recall = real_true / real_count\n",
    "# fake_recall = fake_true / fake_count\n",
    "# real_f1 = 2 * real_precision * real_recall / (real_precision + real_recall)\n",
    "# fake_f1 = 2 * fake_precision * fake_recall / (fake_precision + fake_recall)\n",
    "# print('Test loss: %.4f, Test accuracy: %.4f' % (test_loss / len(test_set), t / len(test_set)))\n",
    "# print('Real Precision: %.4f, Real Recall: %.4f, Real F1: %.4f' % (real_precision, real_recall, real_f1))\n",
    "# print('Fake Precision: %.4f, Fake Recall: %.4f, Fake F1: %.4f' % (fake_precision, fake_recall, fake_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ace8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
